# Deep_Learning_Assignments
## **Backpropagation:**
Implementation of backpropagation to minimize the error given a complex computational graph as shown in the figure below:
![Capture](https://github.com/nagik17/Deep_Learning_Assignments/blob/main/Capture.JPG) 
#### Summary:
Task 1 was about implementing forward and backward propagation functions. \\
Task 2 was to plot the loss with different optimizers such as Vanilla sgd, Momentum based, Adam. \\
As seen, Adam and Momentum updates work better with our data where as Vanilla is not reducing loss as effectively with increase
in epoch. \\
## **CallBacks:**

CNN
LSTM 
Transfer Learning 
BERT
